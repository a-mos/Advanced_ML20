{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, query_ids = load_svmlight_file('l2r/train.txt', query_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split (только для экспериментов)\n",
    "Xs, ys, query_idss = load_svmlight_file('l2r/train.txt', query_id=True)\n",
    "X = Xs[:317023]\n",
    "y = ys[:317023]\n",
    "query_ids = query_idss[:317023]\n",
    "\n",
    "X_test = Xs[317023:]\n",
    "y_test = ys[317023:]\n",
    "query_ids_test = query_idss[317023:]\n",
    "\n",
    "test_query_doc = defaultdict(list)\n",
    "for doc_id, query_id in enumerate(query_ids_test):\n",
    "    test_query_doc[query_id].append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook\n",
    "\n",
    "### Russian\n",
    "confusion_matrix = np.array([[0.75, 0.22, 0.02, 0, 0],\n",
    "                    [0.34, 0.54, 0.11, 0.01, 0],\n",
    "                    [0.07, 0.13, 0.73, 0.06, 0.01],\n",
    "                    [0.04, 0.04, 0.52, 0.32, 0.08],\n",
    "                    [0.03, 0.02, 0.05, 0.08, 0.83]\n",
    "                   ])\n",
    "\n",
    "### Ukranian\n",
    "# confusion_matrix = np.array([[0.88, 0.09, 0.02, 0, 0],\n",
    "#                     [0.26, 0.65, 0.07, 0.01, 0],\n",
    "#                     [0.05, 0.08, 0.78, 0.07, 0.01],\n",
    "#                     [0.03, 0.02, 0.24, 0.60, 0.1],\n",
    "#                     [0.03, 0.02, 0.03, 0.05, 0.86]\n",
    "#                    ])\n",
    "\n",
    "### Yahoo challenge\n",
    "# confusion_matrix = np.array([[0.869, 0.103, 0.02, 0.001, 0.007],\n",
    "#                             [0.016, 0.878, 0.1, 0.005, 0.002],\n",
    "#                             [0.003, 0.098, 0.85, 0.046, 0.004],\n",
    "#                             [0.0, 0.01, 0.094, 0.896, 0.0],\n",
    "#                             [0.0, 0.0, 0.019, 0.016, 0.965]\n",
    "#                            ])\n",
    "\n",
    "def weight(left, right):\n",
    "    w = 0\n",
    "    for u in range(confusion_matrix.shape[0]):\n",
    "        for v in range(confusion_matrix.shape[1]):\n",
    "            if u > v:\n",
    "                w += confusion_matrix[int(left), u] * confusion_matrix[int(right), v]\n",
    "    return w\n",
    "    \n",
    "train_query_doc = defaultdict(list)\n",
    "for doc_id, query_id in enumerate(query_ids):\n",
    "    train_query_doc[query_id].append(doc_id)\n",
    "    \n",
    "w_ij = dict()\n",
    "for query_id in tqdm.notebook.tqdm(train_query_doc):\n",
    "    docs = train_query_doc[query_id]\n",
    "    y_i = y[docs]\n",
    "    y_ij = np.zeros((y_i.shape[0], y_i.shape[0]))\n",
    "    for i in range(y_i.shape[0]):\n",
    "        for j in range(y_i.shape[0]):\n",
    "            y_ij[i][j] = weight(y_i[i], y_i[j])\n",
    "    w_ij[query_id] = y_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss = -log(e^x_i / (e^x_i + e^x_j))\n",
    "### Loss = (x_i - x_j) + log(1 + e^(x_i - x_j))\n",
    "### grad = 1 - e^(x_i - x_j) / (1 + e^(x_i - x_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tqdm.notebook\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "class YetiRank:\n",
    "    def __init__(self, n_trees, max_depth, learning_rate):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "    def compute_grads(self, y_true, y_pred):\n",
    "        grad = np.zeros(y_true.shape[0])\n",
    "        hess = np.zeros(y_true.shape[0])\n",
    "\n",
    "        for query_id in train_query_doc:\n",
    "            docs = np.array(train_query_doc[query_id])\n",
    "            r = y_pred[docs]\n",
    "            r = r.reshape(-1, 1) - r\n",
    "            r = np.clip(r, -30, 30)\n",
    "            dL_dr = 1 - np.exp(r) / (1 + np.exp(r))\n",
    "            grad[docs] = np.sum(w_ij[query_id] * -dL_dr, axis=1)\n",
    "            hess[docs] = np.maximum(np.sum(dL_dr * (1 - dL_dr), axis=1), 1e-16)\n",
    "        return grad, hess\n",
    "\n",
    "    def reweight_tree(self, X, tree, grad, hess):\n",
    "        leaf_index_dct = defaultdict(list)\n",
    "        for sample_index, leaf_index in enumerate(tree.tree_.apply(X)):\n",
    "            leaf_index_dct[leaf_index].append(sample_index)\n",
    "        for leaf_index, sample_indexes in leaf_index_dct.items():\n",
    "            nom = -grad[sample_indexes].sum()\n",
    "            denom = hess[sample_indexes].sum()\n",
    "            if nom == 0 or denom == 0:\n",
    "                tree.tree_.value[leaf_index] = 0.\n",
    "            else:\n",
    "                tree.tree_.value[leaf_index] = nom / denom\n",
    "        return tree\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        predictions = np.zeros_like(y)\n",
    "        for _ in tqdm.notebook.tqdm(range(self.n_trees)):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            grad, hess = self.compute_grads(y, predictions)\n",
    "            tree.fit(X, -grad)\n",
    "            tree = self.reweight_tree(X, tree, grad, hess)\n",
    "            self.trees.append(tree)\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.sum([self.learning_rate * tree.predict(X) for tree in self.trees], axis=0)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YetiRank(n_trees=64, max_depth=10, learning_rate=0.1).fit(X.astype(np.float32), y.astype(np.float32))\n",
    "### Ручной бустинг МЕДЛЕННЫЙ, хоть сколько его не ускоряй и нет многопоточности\n",
    "### Поэтому решил использовать XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(y_true, y_pred):\n",
    "    grad = np.zeros(y_true.shape[0])\n",
    "    hess = np.zeros(y_true.shape[0])\n",
    "\n",
    "    for query_id in train_query_doc:\n",
    "        docs = np.array(train_query_doc[query_id])\n",
    "        r = y_pred[docs]\n",
    "        r = r.reshape(-1, 1) - r\n",
    "        r = np.clip(r, -30, 30)\n",
    "        dL_dr = 1 - np.exp(r) / (1 + np.exp(r))\n",
    "        grad[docs] = np.sum(w_ij[query_id] * -dL_dr, axis=1)\n",
    "        hess[docs] = np.maximum(np.sum(dL_dr * (1 - dL_dr), axis=1), 1e-16)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "params = {\n",
    "         'objective': objective, \n",
    "         'n_estimators': 2048 , \n",
    "         'n_jobs': 16,\n",
    "         'max_depth': 10, \n",
    "         'learning_rate': 0.05\n",
    "         }\n",
    "model = XGBRegressor(**params)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation scoring\n",
    "import tqdm\n",
    "score = []\n",
    "for query_id in tqdm.notebook.tqdm(test_query_doc):\n",
    "    docs = np.array(test_query_doc[query_id])\n",
    "    y_pred_i = y_pred[docs]\n",
    "    y_gt = y_test[docs].astype('int')\n",
    "    if len(y_gt) != 1:\n",
    "        score.append(sklearn.metrics.ndcg_score(y_gt.reshape(1, -1), y_pred_i.reshape(1, -1), k=5))\n",
    "    else:\n",
    "        score.append(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, query_ids_test = load_svmlight_file('l2r/test.txt', query_id=True)\n",
    "y_pred = model.predict(X_test)\n",
    "test_query_doc = defaultdict(list)\n",
    "for doc_id, query_id in enumerate(query_ids_test):\n",
    "    test_query_doc[query_id].append(doc_id)\n",
    "\n",
    "with open(\"submission.csv\", 'w') as write_file:\n",
    "    print(\"QueryId,DocumentId\", file=write_file)\n",
    "    for query_id in test_query_doc:\n",
    "        docs = test_query_doc[query_id]\n",
    "        sorted_docs = np.array(docs)[np.argsort(y_pred[docs])[::-1]]\n",
    "        for doc_id in sorted_docs:\n",
    "            print(f\"{query_id},{doc_id+1}\", file=write_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
